scheme: pcqm4m
model_name: egt_47m
distributed: false         # Set = true for multi-gpu
batch_size: 512            # For 8 GPUs: 512//8=64
model_height: 18
node_width: 640
edge_width: 64
num_heads: 32
num_epochs: 1000
max_lr: 0.0001
attn_dropout: 0.3
lr_warmup_steps: 200000
lr_total_steps: 1000000
node_ffn_multiplier: 1.0
edge_ffn_multiplier: 1.0
upto_hop: 16
dataloader_workers: 1      # For multi-process data fetch
scale_degree: true
num_virtual_nodes: 4
svd_random_neg: true